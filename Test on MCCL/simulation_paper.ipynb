{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_pattern(x):\n",
    "    return [ [1-int(i), int(i)] for i in x ]\n",
    "def create_specific_patterns(mode1,mode2,size):\n",
    "    pats =[]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            pats.append( [[1,1]]*mode1 + bin_to_pattern(str(i)) + [[1,1]]*(mode2-mode1-1) + bin_to_pattern(str(j)) + [[1,1]]*(size-mode1-(mode2-mode1-1)-2) )\n",
    "    return pats\n",
    "def create_specific_patterns3(mode1,mode2,mode3,size):\n",
    "    pats =[]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                pats.append( [[1,1]]*mode1 + bin_to_pattern(str(i)) + [[1,1]]*(mode2-mode1-1) + bin_to_pattern(str(j)) + [[1,1]]*(mode3-(mode2-mode1-1)-mode1-2) + bin_to_pattern(str(k)) + [[1,1]]*(size -mode1-(mode2-mode1-1)-(mode3-(mode2-mode1-1)-mode1-2)-3) )\n",
    "    return pats\n",
    "def create_specific_patterns4(mode1,mode2,mode3,mode4,size):\n",
    "    pats = []\n",
    "    temp_pats = create_specific_patterns3(mode1,mode2,mode3,size)\n",
    "    for p in temp_pats:\n",
    "        for k in range(2):\n",
    "            p_prime = copy.deepcopy(p)\n",
    "            p_prime[mode4] = bin_to_pattern(str(k))[0]\n",
    "            pats.append(p_prime)\n",
    "    return pats\n",
    "def create_specific_patterns5(mode1, mode2, mode3, mode4, mode5, size):\n",
    "    \"\"\"\n",
    "    Generate specific patterns for 5 modes.\n",
    "    \"\"\"\n",
    "    pats = []\n",
    "    temp_pats = create_specific_patterns4(mode1, mode2, mode3, mode4, size)\n",
    "    for p in temp_pats:\n",
    "        for k in range(2):\n",
    "            p_prime = copy.deepcopy(p)\n",
    "            p_prime[mode5] = bin_to_pattern(str(k))[0]\n",
    "            pats.append(p_prime)\n",
    "    return pats\n",
    "def create_specific_patterns8(mode1, mode2, mode3, mode4, mode5, mode6, mode7, mode8, size):\n",
    "    \"\"\"\n",
    "    Generate specific patterns for 8 modes.\n",
    "    \"\"\"\n",
    "    pats = []\n",
    "    temp_pats = create_specific_patterns5(mode1, mode2, mode3, mode4, mode5, size)\n",
    "    for p in temp_pats:\n",
    "        for k in range(2):\n",
    "            p_prime = copy.deepcopy(p)\n",
    "            p_prime[mode6] = bin_to_pattern(str(k))[0]\n",
    "            for l in range(2):\n",
    "                p_prime2 = copy.deepcopy(p_prime)\n",
    "                p_prime2[mode7] = bin_to_pattern(str(l))[0]\n",
    "                for m in range(2):\n",
    "                    p_prime3 = copy.deepcopy(p_prime2)\n",
    "                    p_prime3[mode8] = bin_to_pattern(str(m))[0]\n",
    "                    pats.append(p_prime3)\n",
    "    return pats\n",
    "def dev_pattern(pat):\n",
    "    f = np.array([1])\n",
    "    for i in pat:\n",
    "        f = np.kron(f,i)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Game modeling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(seq):\n",
    "    string = ''\n",
    "    for n in seq:\n",
    "        string+=str(n)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 12\n",
    "sequence_list = np.array([np.array(list(bin(i)[3:]),dtype=np.int32) for i in range(2**n, 2**(n+1))])\n",
    "len(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rules_and_rewards(num_rules=5, rule_length=4, reward_range=(1, 20), sequence_length=12):\n",
    "    \"\"\"\n",
    "    Generate rules, rewards, and starting positions for the rules.\n",
    "    \"\"\"\n",
    "    rules = set()\n",
    "    rewards = []\n",
    "    starting_positions = []\n",
    "\n",
    "    while len(rules) < num_rules:\n",
    "        rule = tuple(np.random.randint(0, 2, size=rule_length))  # Generate a random rule\n",
    "        if rule not in rules:\n",
    "            rules.add(rule)\n",
    "            reward = np.random.randint(reward_range[0], reward_range[1])  # Generate a random reward\n",
    "            rewards.append(reward)\n",
    "            # Generate one or more starting positions for the rule\n",
    "            positions = np.random.choice(range(sequence_length - rule_length + 1), size=np.random.randint(1, 12-rule_length), replace=False)\n",
    "            starting_positions.append(list(positions))\n",
    "\n",
    "    return list(rules), rewards, starting_positions\n",
    "\n",
    "\n",
    "def estimate_cost(sequence, rules, rewards, starting_positions):\n",
    "    \"\"\"\n",
    "    Estimate the cost of a sequence based on the rules, rewards, and starting positions.\n",
    "    \"\"\"\n",
    "    reward = 0\n",
    "    rule_length = len(rules[0])\n",
    "\n",
    "    for rule, rule_reward, positions in zip(rules, rewards, starting_positions):\n",
    "        for k in positions:  # Only check the specified starting positions\n",
    "            if k + rule_length <= len(sequence) and np.all(sequence[k:k + rule_length] == rule):\n",
    "                reward += rule_reward\n",
    "                break  # Stop checking further positions for this rule if it matches\n",
    "\n",
    "    return np.abs(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tests</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_compressive_learning(Phi,sequence_cost,sample_size=200,threshold=20):\n",
    "\n",
    "    #Sample\n",
    "    sample_index = np.random.randint(0,len(sequence_list),sample_size)\n",
    "    sequence_cost_spectrum = np.zeros_like(sequence_cost)\n",
    "    sequence_cost_spectrum[sample_index] = sequence_cost[sample_index]\n",
    "\n",
    "    #Threshold\n",
    "    sequence_cost_spectrum[sequence_cost_spectrum<threshold]=0\n",
    "\n",
    "    #Measurements\n",
    "    y = []\n",
    "    y = np.array(Phi * np.matrix(sequence_cost_spectrum).T).T[0]\n",
    "    y = np.array(y)\n",
    "\n",
    "    #Matching pursuit\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=10)\n",
    "    omp.fit(Phi, y)\n",
    "    coefficients = [ i if i>0 else 0 for i in omp.coef_]\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "nb_rules = 3\n",
    "rules1, rewards1,pos1 = generate_rules_and_rewards(num_rules=nb_rules,rule_length=4)\n",
    "# rules2, rewards2,pos2 = generate_rules_and_rewards(num_rules=3,rule_length=2)\n",
    "# rules3, rewards3,pos3 = generate_rules_and_rewards(num_rules=2,rule_length=3)\n",
    "# rules4, rewards4,pos4 = generate_rules_and_rewards(num_rules=2,rule_length=6)\n",
    "# pos1 = [[0,2,4,6,8]]*nb_rules\n",
    "# pos1 = [np.arange(0,4)]*nb_rules\n",
    "pos1 = [ [i] for i in np.random.randint(0,8,nb_rules)]\n",
    "\n",
    "sequence_cost = []\n",
    "for sequence in sequence_list:\n",
    "    rew = 0\n",
    "    rew += estimate_cost(sequence,rules1, rewards1,pos1)\n",
    "    # rew += estimate_cost(sequence,rules2, rewards2, pos2)\n",
    "    # rew += estimate_cost(sequence,rules3, rewards3, pos3)\n",
    "    # rew += estimate_cost(sequence,rules4, rewards4, pos4)\n",
    "    sequence_cost.append(rew)\n",
    "sequence_cost = np.array(sequence_cost)\n",
    "\n",
    "# noise_rate = 0.5\n",
    "# noise_intensity = 10\n",
    "# mask = np.random.rand(len(sequence_cost)) <= noise_rate\n",
    "# noisy_sequence_cost = sequence_cost.copy()\n",
    "# noisy_sequence_cost[mask]+= np.random.normal(0,noise_intensity,len(sequence_cost)).astype(int)[mask]\n",
    "# noisy_sequence_cost=np.abs(noisy_sequence_cost)\n",
    "\n",
    "plt.bar([i for i in np.arange(len(sequence_list))],sequence_cost,width=1.5)\n",
    "plt.show()\n",
    "# plt.bar([i for i in np.arange(len(sequence_list))],noisy_sequence_cost,width=0.5)\n",
    "# plt.show()\n",
    "ma = np.argmax(sequence_cost)\n",
    "print(ma)\n",
    "# print(sequence_list[ma])\n",
    "print(sequence_cost[ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import dual_annealing\n",
    "\n",
    "# Define the objective function\n",
    "def my_f(x):\n",
    "    \"\"\"\n",
    "    Objective function to minimize.\n",
    "    Converts x to an integer index and returns the negative sequence cost.\n",
    "    \"\"\"\n",
    "    x = int(round(x[0]))  # Ensure x is a single integer index\n",
    "    if 0 <= x < len(sequence_cost):  # Check bounds\n",
    "        return -sequence_cost[x]\n",
    "    else:\n",
    "        return float('inf')  # Return a large value if out of bounds\n",
    "\n",
    "# Define bounds for the single-dimensional problem\n",
    "bounds = [(0, len(sequence_cost) - 1)]  # Single-dimensional bounds\n",
    "\n",
    "# Perform dual annealing optimization\n",
    "results = []\n",
    "for _ in range(200):\n",
    "    res = dual_annealing(my_f, bounds=bounds, maxiter=200,no_local_search=True)\n",
    "    # print(\"Optimization result:\", res)\n",
    "    results.append(int(round(res.x[0])) in np.argpartition(sequence_cost, -20)[-20:])\n",
    "np.average(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random\n",
    "Phi = np.random.rand(250,4096)\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(300):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nearest neighbor quadruplets\n",
    "all_pat = []\n",
    "for i in range(n-3):\n",
    "    all_pat += create_specific_patterns4(i,i+1,i+2,i+3,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(600):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nearest neighbor quintuplets\n",
    "all_pat = []\n",
    "for i in range(n-4):\n",
    "    all_pat += create_specific_patterns5(i,i+1,i+2,i+3,i+4,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(300):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baptiste\\Documents\\PhD\\Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_omp.py:445: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  out = _cholesky_omp(\n",
      "c:\\Users\\Baptiste\\Documents\\PhD\\Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_omp.py:445: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  out = _cholesky_omp(\n",
      "c:\\Users\\Baptiste\\Documents\\PhD\\Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_omp.py:445: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  out = _cholesky_omp(\n",
      "c:\\Users\\Baptiste\\Documents\\PhD\\Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_omp.py:445: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  out = _cholesky_omp(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12333333333333334"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nearest neighbor pairs\n",
    "all_pat = []\n",
    "for i in range(n-1):\n",
    "    all_pat += create_specific_patterns(i,i+1,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(300):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33666666666666667"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All pairs\n",
    "all_pat = []\n",
    "all_pat = []\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "        all_pat += create_specific_patterns(i,j,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(300):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Baptiste\\Documents\\PhD\\Projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_omp.py:445: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "  out = _cholesky_omp(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nearest neighbor triplets\n",
    "all_pat = []\n",
    "for i in range(n-2):\n",
    "    all_pat += create_specific_patterns3(i,i+1,i+2,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(300):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All quadruplets\n",
    "all_pat = []\n",
    "for i in range(n):\n",
    "    for j in range(i+1,n):\n",
    "        for k in range(j+1,n):\n",
    "            for l in range(k+1,n):\n",
    "                all_pat += create_specific_patterns4(i,j,k,l,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "thresh = np.percentile(sequence_cost,90)\n",
    "\n",
    "res = []\n",
    "for _ in range(20):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nearest neighbor octuplets\n",
    "all_pat = []\n",
    "for i in range(n-7):\n",
    "    all_pat += create_specific_patterns8(i,i+1,i+2,i+3,i+4,i+5,i+6,i+7,n)\n",
    "Phi = np.array([dev_pattern(p) for p in all_pat])\n",
    "\n",
    "res = []\n",
    "for _ in range(100):\n",
    "    coefficients = monte_carlo_compressive_learning(Phi,sequence_cost,threshold=thresh)\n",
    "    good_opt = np.intersect1d(np.argpartition(sequence_cost, -20)[-20:],np.nonzero(coefficients)[0])\n",
    "    res.append(1 if len(good_opt) > 0 else 0)\n",
    "np.average(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
